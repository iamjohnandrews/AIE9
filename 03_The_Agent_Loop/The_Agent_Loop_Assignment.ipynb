{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Agent Loop: Building Production Agents with LangChain 1.0\n",
    "\n",
    "In this notebook, we'll explore the foundational concepts of AI agents and learn how to build production-grade agents using LangChain's new `create_agent` abstraction with middleware support.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what an \"agent\" is and how the agent loop works\n",
    "- Learn the core constructs of LangChain (Runnables, LCEL)\n",
    "- Master the `create_agent` function and middleware system\n",
    "- Build an agentic RAG application using Qdrant\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Breakout Room #1:** Introduction to LangChain, LangSmith, and `create_agent`\n",
    "  - Task 1: Dependencies\n",
    "  - Task 2: Environment Variables\n",
    "  - Task 3: LangChain Core Concepts (Runnables & LCEL)\n",
    "  - Task 4: Understanding the Agent Loop\n",
    "  - Task 5: Building Your First Agent with `create_agent()`\n",
    "  - Question #1 & Question #2\n",
    "  - Activity #1: Create a Custom Tool\n",
    "\n",
    "- **Breakout Room #2:** Middleware - Agentic RAG with Qdrant\n",
    "  - Task 6: Loading & Chunking Documents\n",
    "  - Task 7: Setting up Qdrant Vector Database\n",
    "  - Task 8: Creating a RAG Tool\n",
    "  - Task 9: Introduction to Middleware\n",
    "  - Task 10: Building Agentic RAG with Middleware\n",
    "  - Question #3 & Question #4\n",
    "  - Activity #2: Enhance the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ù Breakout Room #1\n",
    "## Introduction to LangChain, LangSmith, and `create_agent`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies\n",
    "\n",
    "First, let's ensure we have all the required packages installed. We'll be using:\n",
    "\n",
    "- **LangChain 1.0+**: The core framework with the new `create_agent` API\n",
    "- **LangChain-OpenAI**: OpenAI model integrations\n",
    "- **LangSmith**: Observability and tracing\n",
    "- **Qdrant**: Vector database for RAG\n",
    "- **tiktoken**: Token counting for text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install dependencies (if not using uv sync)\n",
    "# !pip install langchain>=1.0.0 langchain-openai langsmith langgraph qdrant-client langchain-qdrant tiktoken nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports we'll use throughout the notebook\n",
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Environment Variables\n",
    "\n",
    "We need to set up our API keys for:\n",
    "1. **OpenAI** - For the GPT-5 model\n",
    "2. **LangSmith** - For tracing and observability (optional but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith tracing enabled. Project: AIE9 - The Agent Loop - 9318c008\n"
     ]
    }
   ],
   "source": [
    "# Optional: Set up LangSmith for tracing\n",
    "# This provides powerful debugging and observability for your agents\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE9 - The Agent Loop - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key (press Enter to skip): \") or \"\"\n",
    "\n",
    "if not os.environ[\"LANGCHAIN_API_KEY\"]:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "    print(\"LangSmith tracing disabled\")\n",
    "else:\n",
    "    print(f\"LangSmith tracing enabled. Project: {os.environ['LANGCHAIN_PROJECT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: LangChain Core Concepts\n",
    "\n",
    "Before diving into agents, let's understand the fundamental building blocks of LangChain.\n",
    "\n",
    "### What is a Runnable?\n",
    "\n",
    "A **Runnable** is the core abstraction in LangChain - think of it as a standardized component that:\n",
    "- Takes an input\n",
    "- Performs some operation\n",
    "- Returns an output\n",
    "\n",
    "Every component in LangChain (models, prompts, retrievers, parsers) is a Runnable, which means they all share the same interface:\n",
    "\n",
    "```python\n",
    "result = runnable.invoke(input)           # Single input\n",
    "results = runnable.batch([input1, input2]) # Multiple inputs\n",
    "for chunk in runnable.stream(input):       # Streaming\n",
    "    print(chunk)\n",
    "```\n",
    "\n",
    "### What is LCEL (LangChain Expression Language)?\n",
    "\n",
    "**LCEL** allows you to chain Runnables together using the `|` (pipe) operator:\n",
    "\n",
    "```python\n",
    "chain = prompt | model | output_parser\n",
    "result = chain.invoke({\"query\": \"Hello!\"})\n",
    "```\n",
    "\n",
    "This is similar to Unix pipes - the output of one component becomes the input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see LCEL in action with a simple example\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create our components (each is a Runnable)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that speaks like a pirate.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5\", temperature=0.7)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain them together with LCEL\n",
    "pirate_chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, the capital o‚Äô France be Paris, matey!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain\n",
    "response = pirate_chain.invoke({\"question\": \"What is the capital of France?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Understanding the Agent Loop\n",
    "\n",
    "### What is an Agent?\n",
    "\n",
    "An **agent** is a system that uses an LLM to decide what actions to take. Unlike a simple chain that follows a fixed sequence, an agent can:\n",
    "\n",
    "1. **Reason** about what to do next\n",
    "2. **Take actions** by calling tools\n",
    "3. **Observe** the results\n",
    "4. **Iterate** until the task is complete\n",
    "\n",
    "### The Agent Loop\n",
    "\n",
    "The core of every agent is the **agent loop**:\n",
    "\n",
    "```\n",
    "                          AGENT LOOP                         \n",
    "                                                             \n",
    "      +----------+     +----------+     +----------+         \n",
    "      |  Model   | --> |   Tool   | --> |  Model   | --> ... \n",
    "      |   Call   |     |   Call   |     |   Call   |         \n",
    "      +----------+     +----------+     +----------+         \n",
    "           |                                  |              \n",
    "           v                                  v              \n",
    "      \"Use search\"                   \"Here's the answer\"     \n",
    "```\n",
    "\n",
    "1. **Model Call**: The LLM receives the current state and decides whether to:\n",
    "   - Call a tool (continue the loop)\n",
    "   - Return a final answer (exit the loop)\n",
    "\n",
    "2. **Tool Call**: If the model decides to use a tool, the tool is executed and its output is added to the conversation\n",
    "\n",
    "3. **Repeat**: The loop continues until the model decides it has enough information to answer\n",
    "\n",
    "### Why `create_agent`?\n",
    "\n",
    "LangChain 1.0 introduced `create_agent` as the new standard way to build agents. It provides:\n",
    "\n",
    "- **Simplified API**: One function to create production-ready agents\n",
    "- **Middleware Support**: Hook into any point in the agent loop\n",
    "- **Built on LangGraph**: Uses the battle-tested LangGraph runtime under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Building Your First Agent with `create_agent()`\n",
    "\n",
    "Let's build a simple agent that can perform calculations and tell the time.\n",
    "\n",
    "### Step 1: Define Tools\n",
    "\n",
    "Tools are functions that the agent can call. We use the `@tool` decorator to create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools created:\n",
      "  - calculate: Evaluate a mathematical expression. Use this for any math ca...\n",
      "  - get_current_time: Get the current date and time. Use this when the user asks a...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 2', '10 * 5')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval with restricted globals for safety\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when the user asks about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"The current date and time is: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# Create our tool belt\n",
    "tools = [calculate, get_current_time]\n",
    "\n",
    "print(\"Tools created:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the Agent\n",
    "\n",
    "Now we use `create_agent` to build our agent. The function takes:\n",
    "- `model`: The LLM to use (can be a string like `\"gpt-5\"` or a model instance)\n",
    "- `tools`: List of tools the agent can use\n",
    "- `prompt`: Optional system prompt to customize behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "Type: <class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create our first agent\n",
    "simple_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can perform calculations and tell the time. Always explain your reasoning.\"\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Type: {type(simple_agent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run the Agent\n",
    "\n",
    "The agent is a Runnable, so we can invoke it like any other LangChain component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "First, break it down: 48 = 4 √ó 12. Then 25 √ó 48 = (25 √ó 4) √ó 12 = 100 √ó 12 = 1200.\n",
      "\n",
      "Answer: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with a simple calculation\n",
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 25 * 48?\"}]}\n",
    ")\n",
    "\n",
    "# Print the final response\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "- I looked up the current time: 2026-01-27 09:48:54 (system time). The hour component is 09.\n",
      "- So I divide 100 by the hour: 100 √∑ 9 = 11.11111111111111 (repeating 1).\n",
      "\n",
      "Answer:\n",
      "- Time: 09:48:54 on 2026-01-27\n",
      "- 100 divided by the current hour (9): 11.11111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test with a multi-step question that requires multiple tool calls\n",
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What time is it, and what is 100 divided by the current hour?\"}]}\n",
    ")\n",
    "\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Agent Conversation:\n",
      "==================================================\n",
      "\n",
      "[HUMAN]\n",
      "What time is it, and what is 100 divided by the current hour?\n",
      "\n",
      "[AI]\n",
      "\n",
      "\n",
      "[TOOL]\n",
      "The current date and time is: 2026-01-27 09:48:54\n",
      "\n",
      "[AI]\n",
      "\n",
      "\n",
      "[TOOL]\n",
      "The result of 100 / 9 is 11.11111111111111\n",
      "\n",
      "[AI]\n",
      "- I looked up the current time: 2026-01-27 09:48:54 (system time). The hour component is 09.\n",
      "- So I divide 100 by the hour: 100 √∑ 9 = 11.11111111111111 (repeating 1).\n",
      "\n",
      "Answer:\n",
      "- Time: 09:48:54 on 2026-01-27\n",
      "- 100 divided by the current hour (9): 11.11111111111111\n"
     ]
    }
   ],
   "source": [
    "# Let's see the full conversation to understand the agent loop\n",
    "print(\"Full Agent Conversation:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in response[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, 'type') else 'unknown'\n",
    "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
    "    print(f\"\\n[{role.upper()}]\")\n",
    "    print(content[:500] if len(str(content)) > 500 else content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Agent Responses\n",
    "\n",
    "For better UX, we can stream the agent's responses as they're generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming Agent Response:\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Node: model]\n",
      "I will calculate 15% of 250 by converting 15% to its decimal form (0.15) and multiplying: 0.15 √ó 250.\n",
      "\n",
      "[Node: tools]\n",
      "The result of 0.15 * 250 is 37.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Node: model]\n",
      "To find 15% of 250, convert 15% to a decimal (0.15) and multiply:\n",
      "0.15 √ó 250 = 37.5\n",
      "\n",
      "Answer: 37.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Stream the agent's response\n",
    "print(\"Streaming Agent Response:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for chunk in simple_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Calculate 15% of 250\"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #1:\n",
    "\n",
    "In the agent loop, what determines whether the agent continues to call tools or returns a final answer to the user? How does `create_agent` handle this decision internally?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "The agent continues calling tools as long as the LLM includes `tool_calls` in its response. Once the LLM generates a response without tool calls (just content), that signals the loop should end and the answer should be returned to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "Looking at the `calculate` and `get_current_time` tools we created, why is the **docstring** so important for each tool? How does the agent use this information when deciding which tool to call?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "The **docstring** is the primary way you communicate with the LLM about your tool's capabilities. Poor docstrings ‚Üí poor tool selection ‚Üí failed agent behavior. An analogy is writing tool docstrings is like prompt engineering for your tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #1: Create a Custom Tool\n",
    "\n",
    "Create your own custom tool and add it to the agent! \n",
    "\n",
    "Ideas:\n",
    "- A tool that converts temperatures between Celsius and Fahrenheit\n",
    "- A tool that generates a random number within a range\n",
    "- A tool that counts words in a given text\n",
    "\n",
    "Requirements:\n",
    "1. Use the `@tool` decorator\n",
    "2. Include a clear docstring (this is what the agent sees!)\n",
    "3. Add it to the agent and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "Type: <class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create your custom tool\n",
    "@tool\n",
    "def convert_temperature(temperature: float, unit: str) -> str:\n",
    "    \"\"\"Convert tempratures between Celsius and Fahrenheit\n",
    "    \n",
    "    Args:\n",
    "        temperature: The temperature to convert\n",
    "        unit: The unit to convert to (either 'C' or 'F')\n",
    "    \"\"\"\n",
    "    if unit == 'C':\n",
    "        return f\"{temperature}¬∞C is {temperature * 9/5 + 32}¬∞F\"\n",
    "    elif unit == 'F':\n",
    "        return f\"{temperature}¬∞F is {(temperature - 32) * 5/9}¬∞C\"\n",
    "    else:\n",
    "        return \"Invalid unit. Please use 'C' or 'F'.\"\n",
    "\n",
    "# Add your tool to the tools list and create a new agent\n",
    "tools = [convert_temperature]\n",
    "\n",
    "custom_temp_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can convert temperatures between Celsius and Fahrenheit.\"\n",
    ")\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Type: {type(custom_temp_agent)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "25¬∞C is 77¬∞F.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test your custom tool with the agent\n",
    "response = custom_temp_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 25¬∞C in Fahrenheit?\"}]}\n",
    ")\n",
    "\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ù Breakout Room #2\n",
    "## Middleware - Agentic RAG with Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the basics of agents, let's build something more powerful: an **Agentic RAG** system.\n",
    "\n",
    "Traditional RAG follows a fixed pattern: retrieve ‚Üí generate. But **Agentic RAG** gives the agent control over when and how to retrieve information, making it more flexible and intelligent.\n",
    "\n",
    "We'll also introduce **middleware** - hooks that let us customize the agent's behavior at every step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Loading & Chunking Documents\n",
    "\n",
    "We'll use the same Health & Wellness Guide from Session 2 to maintain continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s)\n",
      "Total characters: 16,206\n"
     ]
    }
   ],
   "source": [
    "# Load the document using our aimakerspace utilities\n",
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
    "\n",
    "# Load the document\n",
    "text_loader = TextFileLoader(\"data/HealthWellnessGuide.txt\")\n",
    "documents = text_loader.load_documents()\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s)\")\n",
    "print(f\"Total characters: {sum(len(doc) for doc in documents):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 41 chunks\n",
      "\n",
      "Sample chunk:\n",
      "--------------------------------------------------\n",
      "The Personal Wellness Guide\n",
      "A Comprehensive Resource for Health and Well-being\n",
      "\n",
      "PART 1: EXERCISE AND MOVEMENT\n",
      "\n",
      "Chapter 1: Understanding Exercise Basics\n",
      "\n",
      "Exercise is one of the most important things you can do for your health. Regular physical activity can improve your brain health, help manage weigh...\n"
     ]
    }
   ],
   "source": [
    "# Split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_texts(documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Setting up Qdrant Vector Database\n",
    "\n",
    "Qdrant is a production-ready vector database. We'll use an in-memory instance for development, but the same code works with a hosted Qdrant instance.\n",
    "\n",
    "Key concepts:\n",
    "- **Collection**: A namespace for storing vectors (like a table in SQL)\n",
    "- **Points**: Individual vectors with optional payloads (metadata)\n",
    "- **Distance**: How similarity is measured (we'll use cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embedding_model.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: wellness_knowledge_base\n"
     ]
    }
   ],
   "source": [
    "# Create Qdrant client (in-memory for development)\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection for our wellness documents\n",
    "collection_name = \"wellness_knowledge_base\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embedding_dim,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 41 documents to vector store\n"
     ]
    }
   ],
   "source": [
    "# Create the vector store and add documents\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert chunks to LangChain Document objects\n",
    "langchain_docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Create vector store\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(langchain_docs)\n",
    "\n",
    "print(f\"Added {len(langchain_docs)} documents to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "\n",
      "--- Document 1 ---\n",
      " memory and learning\n",
      "\n",
      "Chapter 8: Improving Sleep Quality\n",
      "\n",
      "Sleep hygiene refers to habits and practices that promote consistent, quality sleep.\n",
      "\n",
      "Essential sleep hygiene practices:\n",
      "- Maintain a consiste...\n",
      "\n",
      "--- Document 2 ---\n",
      " Avoid caffeine after 2 PM\n",
      "- Exercise regularly, but not too close to bedtime\n",
      "- Limit alcohol and heavy meals before bed\n",
      "\n",
      "Creating an optimal sleep environment:\n",
      "- Temperature: 65-68 degrees Fahrenheit...\n",
      "\n",
      "--- Document 3 ---\n",
      "de for sunlight\n",
      "4. Power pose for 2 minutes\n",
      "5. Healthy snack (nuts, fruit)\n",
      "6. Brief walk around the block\n",
      "7. Upbeat music\n",
      "8. Splash cold water on face\n",
      "\n",
      "Sleep Checklist:\n",
      "- Room temperature 65-68F\n",
      "- Bla...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "test_results = retriever.invoke(\"How can I improve my sleep?\")\n",
    "\n",
    "print(\"Retrieved documents:\")\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Creating a RAG Tool\n",
    "\n",
    "Now we'll wrap our retriever as a tool that the agent can use. This is the key to **Agentic RAG** - the agent decides when to retrieve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool created: search_wellness_knowledge\n",
      "Description: Search the wellness knowledge base for information about health, fitness, nutrition, sleep, and ment...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_wellness_knowledge(query: str) -> str:\n",
    "    \"\"\"Search the wellness knowledge base for information about health, fitness, nutrition, sleep, and mental wellness.\n",
    "    \n",
    "    Use this tool when the user asks questions about:\n",
    "    - Physical health and fitness\n",
    "    - Nutrition and diet\n",
    "    - Sleep and rest\n",
    "    - Mental health and stress management\n",
    "    - General wellness tips\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant wellness information\n",
    "    \"\"\"\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the wellness knowledge base.\"\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        formatted_results.append(f\"[Source {i}]:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "print(f\"Tool created: {search_wellness_knowledge.name}\")\n",
    "print(f\"Description: {search_wellness_knowledge.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Introduction to Middleware\n",
    "\n",
    "**Middleware** in LangChain 1.0 allows you to hook into the agent loop at various points:\n",
    "\n",
    "```\n",
    "                       MIDDLEWARE HOOKS                 \n",
    "                                                        \n",
    "   +--------------+                    +--------------+ \n",
    "   | before_model | --> MODEL CALL --> | after_model  | \n",
    "   +--------------+                    +--------------+ \n",
    "                                                        \n",
    "   +-------------------+                                \n",
    "   | wrap_model_call   |  (intercept and modify calls)  \n",
    "   +-------------------+                                \n",
    "```\n",
    "\n",
    "Common use cases:\n",
    "- **Logging**: Track what the agent is doing\n",
    "- **Guardrails**: Filter or modify inputs/outputs\n",
    "- **Rate limiting**: Control API usage\n",
    "- **Human-in-the-loop**: Pause for human approval\n",
    "\n",
    "LangChain provides middleware through **decorator functions** that hook into specific points in the agent loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging middleware created!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import before_model, after_model\n",
    "\n",
    "# Track how many model calls we've made\n",
    "model_call_count = 0\n",
    "\n",
    "@before_model\n",
    "def log_before_model(state, runtime):\n",
    "    \"\"\"Called before each model invocation.\"\"\"\n",
    "    global model_call_count\n",
    "    model_call_count += 1\n",
    "    message_count = len(state.get(\"messages\", []))\n",
    "    print(f\"[LOG] Model call #{model_call_count} - Messages in state: {message_count}\")\n",
    "    return None  # Return None to continue without modification\n",
    "\n",
    "@after_model\n",
    "def log_after_model(state, runtime):\n",
    "    \"\"\"Called after each model invocation.\"\"\"\n",
    "    last_message = state.get(\"messages\", [])[-1] if state.get(\"messages\") else None\n",
    "    if last_message:\n",
    "        has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls\n",
    "        print(f\"[LOG] After model - Tool calls requested: {has_tool_calls}\")\n",
    "    return None\n",
    "\n",
    "print(\"Logging middleware created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call limit middleware created!\n",
      "  - Thread limit: 10\n",
      "  - Run limit: 5\n"
     ]
    }
   ],
   "source": [
    "# You can also use the built-in ModelCallLimitMiddleware to prevent runaway agents\n",
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "# This middleware will stop the agent after 10 model calls per thread\n",
    "call_limiter = ModelCallLimitMiddleware(\n",
    "    thread_limit=10,  # Max calls per conversation thread\n",
    "    run_limit=5,      # Max calls per single run\n",
    "    exit_behavior=\"end\"  # What to do when limit is reached\n",
    ")\n",
    "\n",
    "print(\"Call limit middleware created!\")\n",
    "print(f\"  - Thread limit: {call_limiter.thread_limit}\")\n",
    "print(f\"  - Run limit: {call_limiter.run_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Building Agentic RAG with Middleware\n",
    "\n",
    "Now let's put it all together: an agentic RAG system with middleware support!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wellness Agent created with middleware!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Reset the call counter\n",
    "model_call_count = 0\n",
    "\n",
    "# Define our tools - include the RAG tool and the calculator from earlier\n",
    "rag_tools = [\n",
    "    search_wellness_knowledge,\n",
    "    calculate,\n",
    "    get_current_time\n",
    "]\n",
    "\n",
    "# Create the agentic RAG system with middleware\n",
    "wellness_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=rag_tools,\n",
    "    system_prompt=\"\"\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about health, fitness, nutrition, sleep, and mental wellness\n",
    "2. Always search the knowledge base when the user asks wellness-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be supportive and encouraging in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\",\n",
    "    middleware=[\n",
    "        log_before_model,\n",
    "        log_after_model,\n",
    "        call_limiter\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Wellness Agent created with middleware!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Wellness Agent\n",
      "==================================================\n",
      "[LOG] Model call #1 - Messages in state: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'evidence-based tips for better sleep; sleep hygiene: consistent schedule, light exposure, caffeine/alcohol timing, screen limits, temperature, noise, bedtime routine, stress management, naps, exercise timing; CBT-I basics; when to seek help for insomnia'}, 'id': 'call_KwkXWU6EdCXbyW0JQUVSYWgF', 'type': 'tool_call'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Model call #2 - Messages in state: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Great question. Here are evidence-based tips to improve sleep:\n",
      "\n",
      "Sleep hygiene basics (Source 2):\n",
      "- Keep a consistent sleep and wake time, even on weekends.\n",
      "- Create a relaxing pre-bed routine (reading, gentle stretching, or a warm bath).\n",
      "- Make your bedroom cool, dark, and quiet.\n",
      "- Limit screen use for 1‚Äì2 hours before bed.\n",
      "- Avoid caffeine after 2 PM.\n",
      "- Exercise regularly, but try to finish workouts well before bedtime.\n",
      "- Limit alcohol in the evening.\n",
      "\n",
      "Relaxation and natural supports (Sources 1 and 3):\n",
      "- Try progressive muscle relaxation, meditation, or deep breathing to wind down.\n",
      "- Some people find chamomile or valerian tea helpful.\n",
      "- Magnesium may support sleep for some, but check with your healthcare provider first.\n",
      "\n",
      "When to seek more help (Source 3):\n",
      "- If sleep trouble happens at least 3 nights per week for 3 months or more, or causes daytime impairment, consider Cognitive Behavioral Therapy for Insomnia (CBT-I) and speak with a healthcare professional.\n",
      "\n",
      "If you‚Äôd like, tell me what‚Äôs hardest for you (falling asleep, staying asleep, waking too early), your typical bedtime routine, caffeine/alcohol use, and screen habits‚ÄîI can help tailor a plan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test the wellness agent\n",
    "print(\"Testing Wellness Agent\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are some tips for better sleep?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with complex query\n",
      "==================================================\n",
      "[LOG] Model call #3 - Messages in state: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'evidence-based tips for stress management and improving sleep hygiene; relaxation techniques; CBT-I; bedtime routine; caffeine, alcohol, screen use; exercise timing; when to seek help'}, 'id': 'call_nadmHDaJdNYkuMC5ktI6PZdh', 'type': 'tool_call'}, {'name': 'calculate', 'args': {'expression': '6 * 7'}, 'id': 'call_XLOOucw3uac10MYj5K1eCpzT', 'type': 'tool_call'}]\n",
      "[LOG] Model call #4 - Messages in state: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "I‚Äôm sorry you‚Äôre dealing with this‚Äîit‚Äôs really common for stress and sleep to feed into each other. Here are some evidence-based steps you can try.\n",
      "\n",
      "Right now (to unwind before bed) [Wellness KB: Insomnia (CBT‚ÄëI); Stress Management]\n",
      "- 5‚Äì10 minutes of deep breathing (e.g., inhale 4, hold 4, exhale 4) and/or progressive muscle relaxation from toes to head.\n",
      "- Try the 5‚Äì4‚Äì3‚Äì2‚Äì1 grounding exercise to settle a busy mind.\n",
      "- Put on calming music and do a brief ‚Äúworry download‚Äù by writing tomorrow‚Äôs to‚Äëdos so your brain can let go.\n",
      "\n",
      "Daily habits that reduce stress and support sleep [Wellness KB: Stress Management; Mindfulness and Meditation]\n",
      "- Practice mindfulness or brief meditation regularly (even 5‚Äì10 minutes) to lower stress reactivity.\n",
      "- Get regular physical activity and short nature walks when you can.\n",
      "- Protect time for social connection, set boundaries, and use simple time‚Äëmanagement (prioritize 1‚Äì3 key tasks/day).\n",
      "- Limit news and social media exposure, especially in the evening.\n",
      "\n",
      "Optional soothing add‚Äëons [Wellness KB: Insomnia (CBT‚ÄëI)]\n",
      "- Some people find chamomile or valerian tea relaxing. Magnesium can help for some, but check with your healthcare provider first‚Äîespecially if you take medications or have health conditions.\n",
      "\n",
      "When to seek extra help\n",
      "- If sleep trouble or high stress lasts more than a few weeks or causes daytime impairment, consider talking with a clinician. Structured CBT‚ÄëI and stress‚Äëmanagement coaching can be very effective.\n",
      "\n",
      "Your math: 6 hours/night for 7 nights = 42 hours total.\n",
      "\n",
      "If you‚Äôd like, tell me what‚Äôs hardest at night (racing thoughts, waking up, tension, etc.), and I can tailor a simple wind‚Äëdown plan for you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test with a more complex query\n",
    "print(\"Testing with complex query\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I'm feeling stressed and having trouble sleeping. What should I do, and if I sleep 6 hours a night for a week, how many total hours is that?\"}]}\n",
    ")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent decision-making (should NOT use RAG)\n",
      "==================================================\n",
      "[LOG] Model call #5 - Messages in state: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] After model - Tool calls requested: [{'name': 'calculate', 'args': {'expression': '125 * 8'}, 'id': 'call_WGsivy5XsozlSFivLRT0Icjq', 'type': 'tool_call'}]\n",
      "[LOG] Model call #6 - Messages in state: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "125 * 8 = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test the agent's ability to know when NOT to use RAG\n",
    "print(\"Testing agent decision-making (should NOT use RAG)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 125 * 8?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Agent\n",
    "\n",
    "The agent created by `create_agent` is built on LangGraph, so we can visualize its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAQAElEQVR4nOydCXwT1fbHz8wkTZd0pysF2lIotCwFCzzgqSjFpwKKiH+kgCCyCA8RBNwQQUBQZFPEBRURfayiLMoiIItQQFoEoUCxlO77vrdJZv5nkjRNS1JpZdKZ5H4/kM9k7s00mfxy7j3nLkfGcRwQCK2NDAgEEUCESBAFRIgEUUCESBAFRIgEUUCESBAFRIiNyU1V/RlTVJKrUtdyKpVGUwsczVIsjUWMHeBThJJxnJoCCkNfFIX/GWBZjuIoWgYajf6A1QBgZIwvBmDxP9AyjlXzB1gfMGymP6l/if5YjUf8MdDasJq2jvGf1kHLOVZFGZ7K7Sm5HePgRPt2dIwc7AoShCJxRB1pN6pP/ZhXVlyrVqGOwMFJpnBgKJpT17CAImT5OjIFqGu0B3JarWIpSqtFFgyyY2SUhj/gaBnF4ktQnTQvF47lbzJtR7O1/IUohtIKkb8UX1P7EjxmZLRaw1LaLwTr8F8Nq397MjsKfxiGd0srKLam/qlcQeOfUlVraipZlZqzU9Btgx2GTvYF6UCEiCZQs3djak2Vxt1LEXG/W/hAZ5A0LBzflX/7WnlVmdo3yOHpl9qCFLB1Ie5am5GfWd22k9MTU6VkP+6G/AzVwc2Z5SXqQc/4du3jBOLGpoX4xYIkOzkzYXEHsF6unS07tSe3Xahy6CQfEDG2K8RNbyf7Bzs+OtEbbICvFiZHDnHv+YB4/RgbFeLnryeF9HQePMYLbIYv3rrtFWA/4kU/ECU02B6bFiW3C3W0KRUiU5YF5aVW/fZDPogSmxPi3s+y8PHx563NNbkbpiwL/vNMMYgSGxOiBtL/qpz0TiDYJjS06+T49aJkEB+2JcQtK1LbBNiDDfPEi/6V5eqbceUgMmxLiGVFtaNnSyPAKxwBnZxifi4AkWFDQty/McvBUQYUWJLXX39979690HyGDBmSkZEBAjBskl9FiQpEhg0JMSe1pkO4pQcYrl27Bs0nKyurqKgIhIGxw5Fr+ui2PBATNiTEmmpN5EMeIAxnzpyZNm3av//97xEjRixatCg/n4+SREZGZmZmLl26dNCgQfi0vLz8s88+mzBhgq7a2rVrq6urdS8fPHjwtm3bpkyZgi85efLk8OHD8eSTTz45d+5cEAAPH7us25UgJmxFiLeuVNIUuPowIAA3btx4+eWX+/Tp8/3337/66qs3b95cvHgxaNWJjwsXLjxx4gQebN++ffPmzePHj1+3bh3WP3LkyMaNG3VXkMvlP/74Y2ho6IYNGwYOHIgV8CS26atXrwYBwMh2dbkGxIStzEfMSqpi5EJ1Dy9dumRvbz9p0iSapn19fcPCwhITE++sNm7cOLR8QUFBuqeXL1+OiYmZNWsWHlMU5erqOm/ePLAIfoH2138vATFhK0KsKtfQjFBCjIiIwEZ29uzZ/fr1e+CBB9q1a4ct7J3V0OydPXsWG240mWq1Gs94eNR3FVC+YCk8vOw4jbiGdm2laeb4MXWhbn2XLl0++ugjLy+v9evXP/XUUzNmzEBrd2c1LMW2GCvs2bMnNjb2+eefNy61s7MDiyFj0AiDmLAVIdor5YZp90IwYMAA7Avu378fe4clJSVoHXU2zwD+EHbv3j169GgUIjbfeKasrAxaieKcaooIsVXw9rdTq1gQhri4OOzt4QEaxWHDhqGriyLDEIxxHZVKVVVV5e2tn3VWW1t76tQpaCXyMmpkciLE1qBLX6VazdVUCtI6Y0OMzvIPP/yAwb+rV6+id4yK9PPzUygUqLxz585hQ4x+TGBg4L59+9LT04uLi5csWYI9y9LS0oqKijsviDXxEd1qvBoIQGZSlUxBhNhKyO3o3w8XggCgO4wN7qpVq3A4ZOrUqU5OTtgXlMl4RxBd6QsXLqCNRHO4fPlydK5HjRqFQcS+ffvOnDkTn0ZFRWGssdEFAwICMJSIQUfsVoIAFGTV+LQV15i7DU2M3bEmvbJE/fw7gWDzrJ/z1+QlwQ7OgkRVW4YNWcQh0T7lpWqweQ58nSVX0KJSIdjUAnsPX7nSVbZ/Y9bwqaany2s0Ggw4myxC3wKjgCY9zeDg4E2bNoEwbNZiskipVOKYocmi8PBwHKEBM6Rcr+wt2FBni7GtNSvpN2v2fZE+44OO5irc2V3TgV85fvEmi7AvaPCF7zllWkwWYQgdu5gmi/A3g96SyaJjW/NuXS2bujwYRIbNLZ7aujKV1XDj3rDmJaRN8PEriSNntPcPsWDw/O6wuTUr0a+2ryjRnD8k1CQrMcOvGuvkKEIVgm2u4pv2XnDc0cLSXNtqCratTLdTME9O9wdRYrsL7DfMuzVktG9n0e/FcU/4Zmmqp7982AsiXdQMNr7lyCdzbwV0dHxihni/nnvCVwtv2zsxY19vDyLG1jdh2vxOSnWF+l+Pt4kYJMltBZvmh/UZmclVnSNcHhkv9p1VyLZ0ELOv4PLpYoqm2nVyeGyCHy390GripYrYY4WFWTWOzrKJbwWCuELXpiFC1HPy+/yEuNKaao2dPaNwwIEHmYurHcVoVEbbY1KUbkNN7UpAGri62Tz8bpzaCY+U9iRNA8s2fAnN7xyrrUBzLKuroN3DkzNcBC/KV2b1F+EnbWt3AcWnwIHxt8TvC6odITL8IZmc0mioqlI1Dh1Vl2uwsqun/MFRXgGdHEAiECE2JmZfYfqtyooiNcvxmwpr1KaEqB1hMdw5SruHMWg3KeaMqhleYqhPUaxGA/xccY5qdBHjytrL8dI0PjBAM9oNao3+kMwOGIZWODDOHrLQXs6hfZQgNYgQLc1LL70UHR3dv39/IBhBNnO3NGq1WjdDjGAMuSOWhgjRJOSOWBoiRJOQO2JpVCqVXC4HQkOIEC0NsYgmIXfE0hAhmoTcEUtDhGgSckcsDQqR9BHvhAjR0hCLaBJyRywNEaJJyB2xNESIJiF3xNIQIZqE3BFLgwFtIsQ7IXfEovDpwlmWYaQwVdWyECFaFNIum4PcFItChGgOclMsCpnxYA4iRItCLKI5yE2xKESI5iA3xaIQIZqD3BSLQoRoDnJTLApxVsxBhGhRiEU0B7kplsbcXq42DhGiRcHBvezsbCDcARGiRcF2uVFqNIIOIkSLQoRoDiJEi0KEaA4iRItChGgOIkSLQoRoDiJEi0KEaA4iRItChGgOIkSLQoRoDiJEi4JC1Gg0QLgDW8w81brg4ArR4p0QIVoa0jqbhAjR0hAhmoT0ES0NEaJJiBAtDRGiSYgQLQ0RokmIEC0NEaJJSOYpCxEREUHTetcQ7zke4+OwYcOWLFkCBOI1W4wePXoAn8aRB0OJFEX5+fmNGzcOCFqIEC3Ec8895+TkZHymZ8+enTt3BoIWIkQLERUVZSw7T0/PMWPGAKEOIkTLMXHiRBcXF91xly5dunfvDoQ6iBAtx/333x8aGooHrq6uY8eOBYIRxGtuwIXDxYW51bXVfF54XVpufZZ4Cvgs9aDNMK/NDs7D55ynOJajtEVQV7lRanpaRrHa7ON4vri46MqVq0onJTrRfBFDsRpOnymc5i+lv7Auaz1ehq1/b4wMNHVhn7r3xv8hlm3wERyU8uBuyuDuksldr4MIUc/JXQXXL5QwDFAyWqUVol5xNK8GTidETpehvk6JfHJ5rV60uej5DPY06PVXr1agGOD0Cef59PQaDUvx2eu1mel19am6ixheQuv+FmvcZBkS12uf8O+K0hZyDYUot6fVtaxcwbywqANIZ4tkIkSeuKMlsUcLHx3X1qOdHVgFFw4WJlwsmb4iSCpaJEKEuCNlF4/nP/taEFgXCbEVF4/mTl0hjc9FnBW4dKowsJsrWB2hkU4yhvp1Rz5IATLWDLU16q793cEacfKQZ6dUgRQgQkRXlFMqKbBG0L+qLJfGBAvSNPP+qbUuIWHxs7EgCYhFtGYwssMRIUoGjrPOhlkbj6Qk0uYRIeoCzVYKpf8vfogQrRkc0TEMG4ocIkQe622aKdI0SwfrHVpCc0icFelAWa0UibNCEA0S+ZERIfJYax+R/2A0cVakg7U2zbzXrCHhG6nAcdY60CmhPiIZa+YD2q3uWT7/wv+t+/C9puvs/mF71CP9oLmQPiJBFEik/0uEaM2QSQ/WzI97dn773Zcr3/t4wcI5BQX5HToEzZ2zoLi4aMV7b6s16j6R/V+Z86abGz/TtrKycs265ZcuxZaVlQZ2CH7ssSdHPPmM7iLJyUnvvb8oJfV2RETkc+MmG1+/sLDgk0/XXI2/XF1d3adPfyxt164DtAh+jRbpI0oGrnl3QS6Xl5eXbd7y+aqVn+zfe0KlUi1/7+2Dh/Z9+cX2/32798rVSzt2fqur+fqbszIz05cuWb1z+4EHHhj84UfvX78RD9r04a+98ZKXl8/mTd9PmzJr+44tKGjdSzQazZy50y5djpsz+81NX+5wd/OY8d8JGZnp0CI4TjIWkQiR70U198tCJU14bioaKgcHh359B2ZlZcyZ/YaPj6+Hh2dEz/tu3bqJdc6dP3PlyqX5cxd27RLu6uo2Nvr57t0jvtmyEYtO/fZrbm7Of2fMxZcEBgbPeulVVLbuyviS1NTkN99Y2q/vALza9Bdnu7i67d69FVoE8ZqtH2xqdQeOjo7u7h4oGt1TBwfH8opyPLh9O9He3j4oqKPhJZ07dU1IuIYHGRlpWOTr66c77+nZxtvbR3eMBhUtbu9efXRPKYpCZV/+8yJYO6SPyNMCz5JfI2/q2AC2tvb2DbZbQMlWVVXiQWlpCerVuEihsNcdoGlEc/vQ4EjjUl2PswXwTbNElgsTIfII8V05OTlVVzdYQVdRWdHG0wsPXFxcdYo0UFlZoTtA64jN/bvL1hqXMnQLV8lrPxcZWZEIHCdIByW0cxi6vX8lJnQKCdWduX79aqC2pfb18cOipKTE4OAQfJqYeDM/P09Xp2PHzlVVVd7evm39A3RnMrMy3FxbaBEpTjIBbdJH5GMcQniWffsO8PcPWLPm3RsJ1zAi89WmT1CIo58Zj0UDBjxoZ2e3as0ylCNKcMmyN9BG6l51X++++MJVq5bm5GSXlBTv2bvrxenjDx3aBy2CTAMj8Ju2L1uy+rPP12H8BWUXHNxp6ZJV6DhjkVKpXP7uuo0bPxr2xIPotUydMuvosYOGF654d92+/btRndeuXUHHPCrqsZEjn4UWwcduJLIyjOx9A+vnJEa/GWJnJbsvNeCnjWnlReopyyWw/Q2xiDxWOx9ROhAhEkQBESKP1a5ZYfhNaUEKECHyWGvTzLEcq5HGYDMRIo/V+mu8y0wsonQge9+0OkSIPFa7eIpMjJUW1mwRyVIBCWHNFpEsnpIQ1rovHekjSgxr3amT9BEJhOZBhEgQBUSI/CCYdFLWNQ+5grF3kkbbTCbGAiOj025IIytOc6mu0Di6yEEKECGCu7f86tkCsEbKilX3PSyNpFpEiDD6lYDSAlXcLyVgXexYleLpax8YLo3EzWSGtp4v3kpSojMvSwAAEABJREFU2MsCuzorvRSsmk8bxqdQ5kA3a0DXz9KdQRiK0zQK+WiLuPpnRsdcg/AQbZQNvEE1qmHwmau7Zn06aDPoatZVoDkm63ZlZlJFlz4u9z/lARKBOCs8N27c2HFu5owRW27+UaSuBZVKlzicVwGl/YYbi4CGRguuaG0KcEO1Btnm+YzilEFkxoJjZJRGzTV6iU5S+rT2dY8A+lfxZ7TZyg3VdEX4BvSp7BlWoaC6RLpKSIVALGJJSYmrq2tMTMyAAQPAIrz88sujR48W6M/t3Llz7dq1crncycnJy8srMDAwIiKiqxYQNzYtxF9++WXr1q2bN28GC7J06dInnniiZ8+eIAyo8r/++oumaVZrIdGk4y/N2dl57969IGJs1FmprOQ3WsjOzrawCpGFCxcKp0Jk6NCh9vb8Bia0FhRiaWlpWloaiBtbtIg7duyoqal57rnnoDVA9bu7uysUChCGqqqq8ePHJycnG844OjqeOnUKxI1tWUS1Wp2bm5uamtpaKkRee+21xMREEAwHB4chQ4YY9oVCQ7Ns2TIQPTYkxO+++w4liB2m+fPnQ+vh4+ODJgqEZOTIkb6+vniA3cS4uLg9e/bouiJixlaEuG/fvvz8/ODgYOHaxLtk5cqVQUHCbr2A/vKgQYPwwN/fHx/XrFmDBvKPP/4AEWP9fUSUIHqpeXl5+PWACMjIyECjKJMJHsHFBvrIkSOGp4WFhaNGjTp06JCdKHdXsXKL+NZbb+EXAFojAeJg+vTp2E8F4TFWIeLh4YFtNHZP0YkG8WG1Qrx4kd/u94UXXpg4cSKICey9oT8BrYGLi0tYWBif62DNGhAZVihEjUYzbtw4lUqFx0L3xlrAxo0bMXwDrYevFhxMAjFhbX1EbIgxRogDd126dAFRgp57QEAAhpqhVcEbhZ3FzMzMzp07gwiwHouI4ouOjsaAhZ+fn2hViKC1rq6uhtYGu4xKpXLx4sXx8fEgAqxHiMeOHcPb2qZNGxA3GFIRj9+KQ+0FBaKYFCz5phmjIR988MG6deuA8A9AX37Dhg2t2GGQvEX88MMP58yZA9IhJSUFxMfcuXOXLFkCrYdULSLGwy5cuDBmzBiQFNg7jIqKOn36NIgVjD5iJBwsjiQtIvolGKl+/PHHQWrgzx6HGUHE4BAUBpjA4kjMIt68eRN7+ujxYWwWCMJw9uzZ/v3719bWWtKpkpJFjIuLQ78YvU7pqhCD7enpLcx5azFQhfi4YsUK3eiUZZCGEJOSkkCbQgfDDeIcs79LsOF78cUXQQosWrRox44dYCkkIMRt27ZhZAEPBJ1hbxkoiurQoYXp6C3P+++/j4+HDh0C4RG1EHWzVJydnVevXg1WgY+Pj+5HJSFwmOrRRx8V2pcQr7OCMep27do9/fTTYEWgB5Cfn6+bryoh8D07ODhgp0guF2onHZFaxKysLHd3dytTIWhXNmHfS3KxWxw4dXJyWr9+fU5ODgiDSC0iy7KtPj9FIFQq1cGDB4cNGya5D9inTx8cRABhEKkQjx07hjEa/ORgpaSlpaEQ27ZtCxKhpqYmNTW1U6dOIAwi/VFevXr1xo0bYL1g93fGjBkVFRUgERQKhXAqBNFaxPj4eIwahoaGglWDEePOnTsrlUoQPRhEw/AF9ihAGERqEcPDw61ehUjv3r0zMjLENmvfJOfOncORVRAMkVrE06dP4xu7//77wQaYNWvW8uXLRW4XcWTSz8+PYYTablykFvHmzZvYTQTb4KOPPiotLRX5GHRAQIBwKgTRCnHgwIE2Yg51YIi7qKgI+2EgSq5cubJgwQIQEpEKETuI3bp1A1uie/fumZmZGPEG8XHt2jU3NzcQEpH2EWNjY4uLi6OiosDGqKysxLgVOjEgJjDMhEEMQbcNEqlFTEpKsuRkOPHg6Ohob2+PvguICRzfE3rzKpEKEcdUWmXlhBgICwsT27rsRx99tLa2FoREpEIMCgrq1asX2CojR44E7T5mIAJwNFI39QaERKRCRDftp59+AtsG3Zd58+ZBa4MD4rt27QKBEakQMah2/vx5sG2wWRDDVmY0TVtgN0eRChGNwfDhw8Hm0cWw1q5dC63H/Pnzjx8/DgIjUiFiHL9v375A0IJ2sRWXXKWmplpgxzCRxhETEhLi4+N1fXYCUlZW5uzsrFarda0kurFyuXz//v1gLYjUImZnZ585cwYIdaAKQbtDDcaWhw0blp+fj0OChw8fBoHRaDSWyUgg3iE+61uw8s/58MMPH3vsMfyVgnb5y7Fjx0Bgfv75Z8ssoRRpdlLd9rpAaMjo0aMN9omiKOzAoCgFvVEZGRk9evQA4RFpHzElJSUmJkZym30JSnR09M2bN43PYH9xzpw5qE6QPiJtmrEPdOLECSAYwbJso0mBOOzWKIfFPScnJ4dlWRAekVrEgoKCq1evPvjgg0Aw4uLFixcuXMBQf3l5eVZWlo9Tb1cXj2efHePv58t/i3XpzI1Tj9dTl+O+/rwh6/2dB9qjirKyL776avbs2fyT+qIG16QaZlVv9EdpmvIOULRp+/fDg+IS4uTJk/EW41tSqVScFvw5Yq/o6NGjQDDi63eSKks1FK1Lek/pE93TwLH8V8rLo+6pLjekPte9VjSNVEfVHTU6yYH2OnUvp+sO8Dxdd173WmMFMTJKo65/LpPjO6HkdlSPge79Hm9qRqO4nJWwsLDvvvuu0cpz8SSNEgkb30jyau8waoYfSGRftPiYkisxhX6BivZhZjMdiauPOG7cOOwGNTpJhliM2fhmUtdIz6hoyagQCR/gOnpe0M/fZMX+UmKujriE6O3tPXToUOMznp6eY8eOBYKWg9/kyuRMRJQrSJCwfm6XTppNpSE6rxlDNsZGMSIiQiSpkcRATmp1Gz97kCa9B3tgz7+23HSp6ITo4uIyfPhw3Yiqh4fH+PHjgVCHqkYts5fw3lQYCMrPMb06TIyfymAUu2kBQh3qWk5dqwLJwmo4Vm266B95zTVVcO5gQc7tqvJSFcYRUO/4lyia4tj6R9DFh3QRLN1Jio8Z8dEEin/Kx6J0B/izkAG+USwaFLhCE6CRMbJPX01CHxqr68NM2riCLlpBMxT+Od070Ucu6g74P8TVB7jQvGIcGC9ur6Q7dHHqP1TArTMILaOFQjz8TW5KQrmqmqXljIyhKTuZnSPDsvyXrw9p1sej6sNR+nCXvkRb1jAWVadUUEB9dEqv5nod1j3SevmC8XGdUsHoCjIZg+LUVKuLclUFmYVxxwoVDkxYP5eBT3iCpKAofVzQ+mi2EA9+nXM7vpyW0c5tnNuGS9K0cLVc6tW8y6dLrpwuiRjk9q/HJfMppJ7RmDL/EZonxM9fu40Xat/DT+kl7CpXQaHsqA69vfEgL6k07tfCa+dLJ70TCJKA07UoUkXfAJribp2VtISqj19JdPZ26jKovaRVaIxXsEv44ECKkX8yPwmkASVps6gfTjTFXQmxJE+99/OMsIeD/MMk1qm6G4L6+Pp29t4w7xaIHkrr2IFkMbitd/L3Qrx1ufJ/K1O6DQmiBdyUrJXxCHAI7ttuw7xEkABS7yia5u+FeOibrE5924G14+DMtAn0+Ow1UbfRfFRCyjrkwyZmLPrfCHHjgtvYL5QrrdcYGuHT0ZWxY7auTAOCMPCulplfUlNCPP59vqqWbd/ThmZhdRoQUJhdk50s7IZDLYZqorcvCbgWOSvXz5f4BtvcIITSw/HnrzJAlPDGRNIRbar5zkrMvgJ8iWegSDMjX7pydN7CfuUVRXCvCbzPp7JcXVKgARHCgeU7iSNGRm359ku4FzTxIzIrxPjfSx1dpDrj6B9ip5D/8m02WAXvLHn9wMG9IA6a+A2ZFWJNpcY3xAqjhneD0ssxL6MarIKEhGsgBUwP8V0/X45m1MFNqJyoyal//nL8y7T0a0on966h/37kocn29k54/sy5XUdObpo+6dMt29/IyU3y8wl5YMCYPr312Y5+OrQ+9vIBhZ1jrx7/8W7THgTDN8StML0UxEfdtI675aHBkfj4waqln362dv/eE3h85szJb7ZsTEm97erqFhIS+vJLr/n46NfnN1Gk/+sct/uHbYcP/5SWntKhfVBk5L8mPT/9XuW8MG0Rb8eXMzKhQjb5BWmfb35JpaqZOfXLCdHvZ+X89emm6RrtcjRGJq+qKtvz86r/G/HmB0vO9ej28M49y4qK+VYy5vfdMb9/P3Lo/Jenfe3p7n/k+FcgGBjEYRjqZpzoEuU1d1Tl0AF+/6D58xbqVBgbd/7txfMfeWTozu0HFi18Lycna91H7+lqNlFk4Icftn/3v02jno7evvWn4cOf/vnAnu07tkCz4Mx+BNNCrCzRyORCzZm9ePmQjJFPHPO+j1egr3fwM08uyMhKuHr9pK5Uo1ENeWhyh3bdcSwrMmIo/gozsvjtDU6f3dkjfDBK09HRBW1kSHAkCApNZaeIL9NEE2Nkd8Gmrz994P6HUUlo88LDe8yY/sq5c6dvaNvuJooMXP7zYmho2H/+M8zNzX3Y0Kc2fLy5X9+B0BxQheYW65tWW61KI1ycANvldgFhTk76Va4e7n6eHgG3Uy4ZKrRvG647cHTgffaq6jKUY35hmo93kKFOgL+w253TFFVdpQbrIinpry5dwg1PQzuH4eONG/FNFxno1q1nXNz5lR8sOXR4f0lpSVv/gJCQ5i0n4sOIZn5HZqaB8coVKkxQVV2elnENgy/GJ0vL6td33TmuX11TwbIahcLRcMbOzgEEhQLaugbXy8vLa2pqFIr6SIijI38/KysrmigyvgLaS0dHpzMxJ99f+Y5MJhs0aMi0KbPatLk34x2mhahQMBUgVCDN2dkzqEPEfx6eanzSyampJZL2CieUhUpV78nW1Aq7aR/HcvYO4lvQY36s9m+xt+d1Vl1d39+o0OrM06NNE0XGV6BpGltk/JecnHTx4u+bt2ysqChfvuzebKtsWojOHvK8TKEW6fj7dIq7fCA4sJdhR4fs3CQvz6a8YLSR7m5+yalXHqzrk1xPEHYbT5blfIMENrrNh+L7Ui1sqfj81527xsf/aTijOw7u2KmJIuMroL/cuXPXoKCOgYHB+K+svOznAz9Cc2j2fMSQHkqNSqgeEkZkWJbdd3BtbW11bl7KT4c/Xv1xdFbO30zB6tkt6sq14ziggse//rYlJV3A3KW15RrsmoT0dASR0dzZNwqFwsvLOzb23B+XYtVq9VMjRp8+c2L37m2lZaV45pNP1/Tu1adTCJ8Xu4kiA8d+PYSedUzMKewgoivz2+lfu4X3hGZiboa5aYsY3MORoqnSvBoXASZjo9s7b+bW4799u+6zCbl5ye0Dwp8ZseBvnY+oB5+vqCjac2D1dzsXYMv+xGOzt+56W6AdpHJvF8kVEl4+bMzY6Elfb/7s9wsx27b+hNGZvPzcHbu+/fiT1RgjjLzvX1Mmz9RVa6LIwNxX3vp4w6oFC18BfkwfmngAAAPXSURBVMm5J7bRz4waB81B66yY/srM7gb29eJkFpiO/fzB9kg4kerTwX7EDD8QGZ++eisgxHHQaNG9sbtk8+LEp15sGxBqos9j9ncf8YB7dblIZ0MJjUqlGfGiSL9szkpnaJtdxdfrYdfffynISij2CzW9rV1xSc6qj6NNFjkolFU1pvc48fUKnjn1C7h3vPXuYHNFOFrDMCY+YGD7HpPHm/X1bv2e7ephJ9KtdCW+qlnrrDSnj6gj8hGP84cKzQnRWen5yoxvTRahF2JnZ3rmDk3f4x0Zzb0H/m2oauzkJvq4MqapHd2qSqomvhcCooQCaS+e0oafTJc0JYv7Hna7crrkdmx2UKSJfevR2Hi4t34P8t6+h4RTaW1DHBmxbj2o9Zol3DTzSwXY5i8VQCa+3aG6rKYkyxIpX1qd9Ph8mQyemiFe/8y8QZE8f98Vmr4iOC0+F6ydrOtFZXkVLywNBBHDmR2qlQaU4eEO7qJPzsD0lR2vHrldmCG6aVH3ivQ/80vzyqa/HwwEIeEMD3dwV84hw8DMNSGZ13OxvwhWR8JvaRXFFdNWBIHooWiQ9H5g+jQZpmhGlGLm6hCKU984kZKVUAhWQfKlXLT0rm6yaSukYQs5VtpxxOZPAzMD+i6xR4rjfi0szipzUDq0CXZTekhnc/s6itIrClKKqytrFY7MU9PatQ2VzJ5S2s1HrXNdc7OjepFD3PBf7NGSa2dLUv7IxGgCI6NpbDOw1WAo7o4JuI3zH9WdhCYXRhq29GyUT6bxC+saqkZ1Gl2ZZjiOpTVqDbCcWsUyDKV0l0c92zawm+jm1zSNdqNOSe85YnaCeQvDy5FRrpHaJAuJf1QkXikryVNVVWj4GNcdQqQZYI1nNmrTdNHayUzGlRvsMwv6HYjvrNboDEVzOikap4vjX6vdurb+Q8opRk7J5PI2/vahfZRtO9roMlkx80/HOUJ6OeE/IBD+GSLN10wwidyOkcklvIBBJqPAzAIMIkQpIbenaiotkbRWILDbHxBs2ru1kumfNkJgV+eC7BqQJjH78hUODJgx6ESIUuLBpz3QBft1qyRHXFPiSx9+xttcqUgThxOaYMuyVIqmew1q0yFcAu5/eTF38Wheyo2yCW8FOrma7eASIUqSXesyCrNrNWpWozH6+hqHi02Fj7m7nV1rOuR31y/XQTN8uiYHpeyRsT7+IU39bIgQpUwtVFUZBWkNieD0T7WPXMMQP+qi0YxAk9VM1gR9GNjUmAHdIJZrgGEclHA3ECESRAEJ3xBEAREiQRQQIRJEAREiQRQQIRJEAREiQRT8PwAAAP//eSPSiAAAAAZJREFUAwAQ7U8C3q5N5AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the agent graph\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(wellness_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"\\nAgent structure:\")\n",
    "    print(wellness_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #3:\n",
    "\n",
    "How does **Agentic RAG** differ from traditional RAG? What are the advantages and potential disadvantages of letting the agent decide when to retrieve information?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "Traditional RAG = Simple, predictable, but inflexible <br>\n",
    "Agentic RAG = Powerful, adaptive, but requires careful design to prevent the agent from \"going rogue\" and skipping retrieval when it shouldn't. It is about finding the right balance between your agent being smart enough to skip unnecessary retrievals, but not so \"confident\" that it hallucinates answers it should have looked up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "Looking at the middleware examples (`log_before_model`, `log_after_model`, and `ModelCallLimitMiddleware`), describe a real-world scenario where middleware would be essential for a production agent. What specific middleware hooks would you use and why?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "When an agent is doing anything with UI and you want a designer to approve the previous step before the agent moves on. Any type of human-in-the-loop you would wantt to use `log_before_model`, so human can abort process and save resources (e.g. time, money, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #2: Enhance the Agentic RAG System\n",
    "\n",
    "Now it's your turn! Enhance the wellness agent by implementing ONE of the following:\n",
    "\n",
    "### Option A: Add a New Tool\n",
    "Create a new tool that the agent can use. Ideas:\n",
    "- A tool that calculates BMI given height and weight\n",
    "- A tool that estimates daily calorie needs\n",
    "- A tool that creates a simple workout plan\n",
    "\n",
    "### Option B: Create Custom Middleware\n",
    "Build middleware that adds new functionality:\n",
    "- Middleware that tracks which tools are used most frequently\n",
    "- Middleware that adds a friendly greeting to responses\n",
    "- Middleware that enforces a response length limit\n",
    "\n",
    "### Option C: Improve the RAG Tool\n",
    "Enhance the retrieval tool:\n",
    "- Add metadata filtering\n",
    "- Implement reranking of results\n",
    "- Add source citations with relevance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wellness Agent created with BMI tool!\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Implement your enhancement below\n",
    "@tool\n",
    "def calculate_bmi(height: float, weight: float) -> str:\n",
    "    \"\"\"Calculate the Body Mass Index (BMI) given a person's height and weight.\n",
    "    \n",
    "    Args:\n",
    "        height: The height in centimeters\n",
    "        weight: The weight in kilograms\n",
    "    \"\"\"\n",
    "    bmi = weight / (height / 100) ** 2\n",
    "    return f\"Your BMI is {bmi:.2f}. This is considered {get_bmi_category(bmi)}.\"\n",
    "\n",
    "def get_bmi_category(bmi: float) -> str:\n",
    "    \"\"\"Get the BMI category based on the BMI value.\n",
    "    \n",
    "    Args:\n",
    "        bmi: The Body Mass Index value  \n",
    "    \"\"\"\n",
    "    if bmi < 18.5:\n",
    "        return \"underweight\"\n",
    "    elif 18.5 <= bmi < 24.9:\n",
    "        return \"normal weight\"\n",
    "    elif 25 <= bmi < 29.9:\n",
    "        return \"overweight\"\n",
    "    else:\n",
    "        return \"obese\"\n",
    "\n",
    "# Add your tool to the tools list and create a new agent\n",
    "tools = [calculate_bmi]\n",
    "\n",
    "wellness_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\",\n",
    ")   \n",
    "\n",
    "print(\"Wellness Agent created with BMI tool!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Your BMI is 27.9, which falls in the overweight range (25‚Äì29.9). For your height (1.93 m), a BMI in the ‚Äúhealthy‚Äù range would correspond to roughly 69‚Äì93 kg. Note that BMI is a screening tool and doesn‚Äôt account for muscle mass or body composition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Test your enhanced agent here\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my BMI if I am 193cm tall and weigh 104kg?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wellness Agent created with BMI tool!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import before_model, after_model\n",
    "\n",
    "# Track how many model calls we've made\n",
    "model_call_count = 0\n",
    "\n",
    "@before_model\n",
    "def log_before_model(state, runtime):\n",
    "    \"\"\"Called before each model invocation.\"\"\"\n",
    "    global model_call_count\n",
    "    model_call_count += 1\n",
    "    message_count = len(state.get(\"messages\", []))\n",
    "    print(f\"Good Day Healthy person! [LOG] Model call #{model_call_count} - Messages in state: {message_count}\")\n",
    "    return None  # Return None to continue without modification\n",
    "\n",
    "@after_model\n",
    "def log_after_model(state, runtime):\n",
    "    \"\"\"Called after each model invocation.\"\"\"\n",
    "    last_message = state.get(\"messages\", [])[-1] if state.get(\"messages\") else None\n",
    "    if last_message:\n",
    "        has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls\n",
    "        print(f\"Go Be Better Healthy person! [LOG] After model - Tool calls requested: {has_tool_calls}\")\n",
    "\n",
    "# Create the agent with middleware\n",
    "wellness_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\",\n",
    "    middleware=[log_before_model, log_after_model]\n",
    ")\n",
    "\n",
    "print(\"Wellness Agent created with BMI tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Day Healthy person! [LOG] Model call #1 - Messages in state: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go Be Better Healthy person! [LOG] After model - Tool calls requested: [{'name': 'calculate_bmi', 'args': {'height': 193, 'weight': 104}, 'id': 'call_cwMa9a9j6KQaVtgQEgbw8h2V', 'type': 'tool_call'}]\n",
      "Good Day Healthy person! [LOG] Model call #2 - Messages in state: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go Be Better Healthy person! [LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE for model_call_count:  2\n",
      "==================================================\n",
      "Your BMI is about 27.9, which falls in the overweight range (25.0‚Äì29.9). Note: BMI is a screening tool and doesn‚Äôt account for muscle mass, body composition, or distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "#test the middleware agent\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my BMI if I am 193cm tall and weigh 104kg?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE for model_call_count: \", model_call_count)\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
